{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "randomforestclassier(分类器)和randomforestregression(回归器)采用了bagging的融合思想"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import ShuffleSplit, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(boston.data, boston.target,test_size=0.2,random_state=42)\n",
    "boston[\"feature_names\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 学习器的属性和方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestRegressor(n_estimators=10)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8795148165967526\n",
      "0.8795148165967526\n"
     ]
    }
   ],
   "source": [
    "# 评估模型的准确率\n",
    "# 方法一：利用学习器内置的score函数,默认为R2\n",
    "print(clf.score(X_test, Y_test))\n",
    "\n",
    "# 方法二：采用metric中内置的评价函数\n",
    "from sklearn.metrics import r2_score\n",
    "Y_pred = clf.predict(X_test)\n",
    "print(r2_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "10\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 学习器的特征数量\n",
    "print(clf.n_features_)\n",
    "# 学习器的弱学习器数量\n",
    "print(clf.n_estimators)\n",
    "# 学习期的输出维度\n",
    "print(clf.n_outputs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 模型调参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“““\n",
    "RandomForestRegressor(n_estimators=, criterion=, max_features=, max_depth=, min_samples_split=, min_samples_leaf=, \n",
    "                     min_weight_fraction_leaf=, min_impurity_split=, min_impurity_decrease=, bootstrap=,oob_score=, random_state=)\n",
    "\n",
    "bagging框架相关参数：\n",
    "n_estimators：子树个数\n",
    "bootstrap：是否自助采样（有放回的），默认False\n",
    "oob_score：是否采用袋外评分\n",
    "\n",
    "决策树相关参数：\n",
    "criterion：代价函数，默认mse\n",
    "max_features：子树寻找最优分叉的最大随机特征数，默认auto，可设为‘sqrt’，‘log2’，或分数占比\n",
    "max_depth：子树最大深度\n",
    "min_samples_split：内部节点支持分叉时的最小样本数\n",
    "min_samples_leaf：叶节点的最小样本数\n",
    "min_weight_fraction_leaf：限制了叶子节点所有样本权重和的最小值\n",
    "min_impurity_split: 通过纯度来限制划分\n",
    "min_impurity_decrease ：通过纯度增益来限制划分\n",
    "”””"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parms of best estimator is {'criterion': 'mse', 'max_depth': 4, 'n_estimators': 4}\n",
      "The score of best estimator is 0.7921206760990241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "score = make_scorer(r2_score)\n",
    "parms = {\"max_depth\":range(1, 5), \"criterion\": np.array([\"mse\", \"mae\"]), \"n_estimators\": range(4,8)}\n",
    "clf_grid = GridSearchCV(RandomForestRegressor(), scoring=score, param_grid=parms, cv=5)\n",
    "grid = clf_grid.fit(X_train, Y_train)\n",
    "best_estimator = grid.best_estimator_\n",
    "print(\"The parms of best estimator is {}\".format(grid.best_params_))\n",
    "print(\"The score of best estimator is {}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 特征重要性排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法一： 按照不纯度降低（对于回归问题，即方差降低）的程度进行排序（对随机森林中的每棵树进行平均）\n",
    "这种方法有两个注意事项：\n",
    "1）基于不纯度降低的特征选择将会偏向于选择那些具有较多类别的变量[bias]https://link.springer.com/article/10.1186/1471-2105-8-25\n",
    "2) 当存在相关特征时，一个特征被选择后，与其相关的其他特征的重要度则会变得很低，因为他们可以减少的不纯度已经被前面的特征移除了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.6716, 'RM'), (0.2119, 'LSTAT'), (0.0617, 'DIS'), (0.0128, 'CRIM'), (0.0111, 'NOX'), (0.011, 'PTRATIO'), (0.0086, 'B'), (0.0055, 'TAX'), (0.0052, 'INDUS'), (0.0006, 'RAD'), (0.0, 'ZN'), (0.0, 'CHAS'), (0.0, 'AGE')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Features sorted by their score:\")\n",
    "features = boston[\"feature_names\"]\n",
    "print(sorted(zip(map(lambda x: round(x, 4), best_estimator.feature_importances_), features), reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法二：准确率降低\n",
    "直接测量每种特征对模型预测准确率的影响，基本思想是重新排列某一列特征值的顺序，观测降低了多少模型的准确率。对于不重要的特征，这种方法对模型准确率的影响很小，但是对于重要特征却会极大降低模型的准确率。\n",
    "可以利用袋外数据（oob）对每个特征值改变对预测准确度的影响程度进行权重衡量。具体做法是：\n",
    "（1）对于随机森林中的每一颗决策树,使用相应的OOB(袋外数据)数据来计算它的袋外数据误差,记为errOOB1\n",
    "（2）随机地对袋外数据OOB所有样本的特征X加入噪声干扰，再次计算它的袋外数据误差,记为errOOB2\n",
    "（3）假设随机森林中有Ntree棵树,那么对于特征X的重要性=∑(errOOB2-errOOB1)/Ntree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.887, 'LSTAT'), (0.5428, 'RM'), (0.0927, 'DIS'), (0.0535, 'CRIM'), (0.0453, 'NOX'), (0.0193, 'TAX'), (0.0171, 'PTRATIO'), (0.0139, 'AGE'), (0.0053, 'INDUS'), (0.0045, 'B'), (0.0008, 'ZN'), (0.0004, 'RAD'), (-0.0003, 'CHAS')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "X = boston[\"data\"]\n",
    "Y = boston[\"target\"]\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "score_dict = defaultdict(list)\n",
    "features = boston[\"feature_names\"]\n",
    "\n",
    "rs = ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "for train_idx, test_idx in rs.split(X):\n",
    "    X_train_iter, X_test_iter = X[train_idx], X[test_idx]\n",
    "    Y_train_iter, Y_test_iter = Y[train_idx], Y[test_idx]  \n",
    "    rf_iter = rf.fit(X_train_iter, Y_train_iter)\n",
    "    acc_iter = r2_score(Y_test_iter, rf_iter.predict(X_test_iter))\n",
    "    for i in range(X.shape[1]):\n",
    "        X_t = X_test_iter.copy()\n",
    "        np.random.shuffle(X_t[:, i])     # 调整第i个特征\n",
    "        shuff_acc = r2_score(Y_test_iter, rf_iter.predict(X_t))\n",
    "        score_dict[features[i]].append((acc_iter - shuff_acc)/acc_iter)\n",
    "\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted([(round(np.mean(score), 4),feat) for feat, score in score_dict.items()],reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
